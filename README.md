List of Interesting Neural Networks: A list of various (interesting and not necessarily practical) things done with neural networks. Open for suggestions and additions.

# Images

* [Neural Style Transfer](https://github.com/jcjohnson/neural-style) (see also [Cubist Mirror](https://github.com/genekogan/CubistMirror), an art project utilizing the style transfer; original implementation is in Torch, other variants include [TensorFlow](https://github.com/anishathalye/neural-style), [Keras](https://github.com/titu1994/Neural-Style-Transfer))
* [Deep Photo Style Transfer](https://github.com/luanfujun/deep-photo-styletransfer)
* [Pix2Pix](https://github.com/phillipi/pix2pix) (see also [CycleGAN](https://github.com/junyanz/CycleGAN) for code which makes use of Generative Adversarial Networks; original implementation is in Torch, a [TensorFlow version](https://github.com/affinelayer/pix2pix-tensorflow) is available; also take a look at the [online version](https://affinelayer.com/pixsrv/) for some nightmarish cats, weird handbags and shoes, along with building facades)
* [DeepDream](https://github.com/google/deepdream)
* [PyTorch Implementation of the Coupled GAN algorithm for Unsupervised Image-to-Image Translation](https://github.com/mingyuliutw/UNIT)

# Audio

* [[Overview of] Neural Nets for Generating Music (Blog Post)](https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0)
* [Deep Learning Techniques for Music Generation - A Survey](https://arxiv.org/abs/1709.01620)
* [Deep Learning for Music (DL4M) (a curated list of papers/code related to application of DL to music analysis/processing/generation)](https://github.com/ybayle/awesome-deep-learning-music#code-without-articles)
* [WaveNet (Blog Post)](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) (code: a [Fast TensorFlow implementation](https://github.com/tomlepaine/fast-wavenet), a [Keras implementation](https://github.com/basveeling/wavenet), a [TensorFlow implementation](https://github.com/ibab/tensorflow-wavenet)), a [PyTorch implementation](https://github.com/vincentherrmann/pytorch-wavenet) (seems abandoned, though), an [in-progress PyTorch port of the Fast Tensorflow WaveNet](https://github.com/dhpollack/fast-wavenet.pytorch/tree/master/wavenet)
* [NSynth (Blog Post)](https://magenta.tensorflow.org/nsynth) (code available [here](https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth); also check out this [online playable version](https://aiexperiments.withgoogle.com/sound-maker/view/))
* [Generating sound using RNNs](https://github.com/johnglover/sound-rnn)
* [Audio Style Transfer](https://github.com/DmitryUlyanov/neural-style-audio-tf) (original code uses TensorFlow, other variants include [Torch](https://github.com/DmitryUlyanov/neural-style-audio-torch) and [Lasagne](https://github.com/vadim-v-lebedev/audio_style_tranfer))
* [Performance RNN (Blog Post)](https://magenta.tensorflow.org/performance-rnn) (code available [here](https://github.com/tensorflow/magenta/tree/master/magenta/models/performance_rnn))
* [GRUV](https://github.com/MattVitelli/GRUV)

# Video

* [Artistic Style Transfer for Videos](https://github.com/manuelruder/artistic-videos)